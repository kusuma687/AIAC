{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVRYtXd0UMsMXprBJPZj6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kusuma687/AIAC/blob/main/2403A52096_NLP_ASSIGNMENT_6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab Objectives:\n",
        "\n",
        "o Understand domain mismatch in HMMs\n",
        "\n",
        "o Analyze tag transition patterns in technical writing\n",
        "\n",
        "Tasks:\n",
        "\n",
        "1. Collect 20–30 research abstracts.\n",
        "\n",
        "2. Automatically POS-tag them using NLTK.\n",
        "\n",
        "3. Treat the tagged data as training data for HMM.\n",
        "\n",
        "4. Compute:\n",
        "\n",
        "a) Transition probabilities\n",
        "\n",
        "b) Emission probabilities\n",
        "\n",
        "c) Analyze:\n",
        "\n",
        " o Most frequent tag transitions\n",
        "\n",
        "o Apply HMM tagging to a new abstract sentence."
      ],
      "metadata": {
        "id": "v4ofV53ONxdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Collect 20–30 research abstracts.**"
      ],
      "metadata": {
        "id": "VIZkdZe6Q_f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "APtCbNlZNQz3",
        "outputId": "d3d5416a-6556-40e9-c77f-11d0da64ca39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of abstracts: 25\n",
            "\n",
            "Sample abstract:\n",
            "\n",
            "Stereo matching is one of the widely used techniques for inferring depth from\n",
            "stereo images owing to its robustness and speed. It has become one of the major\n",
            "topics of research since it finds its applications in autonomous driving,\n",
            "robotic navigation, 3D reconstruction, and many other fields. Finding pixel\n",
            "correspondences in non-textured, occluded and reflective areas is the major\n",
            "challenge in stereo matching. Recent developments have shown that semantic cues\n",
            "from image segmentation can be used to improve the results of stereo matching.\n",
            "Many deep neural network architectures have been proposed to leverage the\n",
            "advantages of semantic segmentation in stereo matching. This paper aims to give\n",
            "a comparison among the state of art networks both in terms of accuracy and in\n",
            "terms of speed which are of higher importance in real-time applications.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"arxiv_data.csv\")\n",
        "\n",
        "# Use correct column name\n",
        "abstract_column = \"summaries\"\n",
        "\n",
        "# Select 25 abstracts\n",
        "abstracts = df[abstract_column].dropna().astype(str).head(25).tolist()\n",
        "\n",
        "print(\"Number of abstracts:\", len(abstracts))\n",
        "print(\"\\nSample abstract:\\n\")\n",
        "print(abstracts[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Automatically POS-tag them using NLTK.**"
      ],
      "metadata": {
        "id": "fmSLKuTPSB1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Simple tokenizer\n",
        "def tokenize(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", text)\n",
        "\n",
        "# Simple rule-based POS tagger\n",
        "def simple_pos_tag(tokens):\n",
        "    tagged = []\n",
        "    for word in tokens:\n",
        "        if word.lower() in ['the', 'a', 'an']:\n",
        "            tag = 'DT'\n",
        "        elif word.endswith('ing'):\n",
        "            tag = 'VBG'\n",
        "        elif word.endswith('ed'):\n",
        "            tag = 'VBD'\n",
        "        elif word[0].isupper():\n",
        "            tag = 'NNP'\n",
        "        else:\n",
        "            tag = 'NN'\n",
        "        tagged.append((word, tag))\n",
        "    return tagged\n",
        "\n",
        "# Tag all abstracts\n",
        "tagged_data = []\n",
        "\n",
        "for abstract in abstracts:\n",
        "    tokens = tokenize(abstract)\n",
        "    tagged = simple_pos_tag(tokens)\n",
        "    tagged_data.extend(tagged)\n",
        "\n",
        "print(\"Sample tagged output:\")\n",
        "print(tagged_data[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xTe6yoOzRMJ-",
        "outputId": "64c9f44a-40f8-43f6-9d56-2f61453a145d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample tagged output:\n",
            "[('Stereo', 'NNP'), ('matching', 'VBG'), ('is', 'NN'), ('one', 'NN'), ('of', 'NN'), ('the', 'DT'), ('widely', 'NN'), ('used', 'VBD'), ('techniques', 'NN'), ('for', 'NN'), ('inferring', 'VBG'), ('depth', 'NN'), ('from', 'NN'), ('stereo', 'NN'), ('images', 'NN'), ('owing', 'VBG'), ('to', 'NN'), ('its', 'NN'), ('robustness', 'NN'), ('and', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Treat the tagged data as training data for HMM.**"
      ],
      "metadata": {
        "id": "3-xJUNYTSSIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "tag_counts = defaultdict(int)\n",
        "\n",
        "previous_tag = None\n",
        "\n",
        "for word, tag in tagged_data:\n",
        "    tag_counts[tag] += 1\n",
        "    emission_counts[tag][word] += 1\n",
        "\n",
        "    if previous_tag is not None:\n",
        "        transition_counts[previous_tag][tag] += 1\n",
        "\n",
        "    previous_tag = tag\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KUdgw9I9SN6r",
        "outputId": "b8a5e6a8-38c3-46e7-cf8d-b8ce2690ff28"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Compute:**\n",
        "\n",
        "**a) Transition probabilities**"
      ],
      "metadata": {
        "id": "x7dUCmy5ShfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transition_prob = defaultdict(dict)\n",
        "\n",
        "for prev_tag in transition_counts:\n",
        "    total = sum(transition_counts[prev_tag].values())\n",
        "    for tag in transition_counts[prev_tag]:\n",
        "        transition_prob[prev_tag][tag] = transition_counts[prev_tag][tag] / total\n",
        "\n",
        "print(\"Sample Transition Probabilities:\\n\")\n",
        "\n",
        "for prev_tag in list(transition_prob.keys())[:3]:\n",
        "    for tag in list(transition_prob[prev_tag].keys())[:3]:\n",
        "        print(f\"P({tag} | {prev_tag}) = {transition_prob[prev_tag][tag]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q0uGHanXSbWY",
        "outputId": "d1dc620b-c7dc-4650-9c06-f4231b4bf2a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Transition Probabilities:\n",
            "\n",
            "P(VBG | NNP) = 0.045\n",
            "P(NN | NNP) = 0.623\n",
            "P(VBD | NNP) = 0.057\n",
            "P(NN | VBG) = 0.689\n",
            "P(NNP | VBG) = 0.124\n",
            "P(VBG | VBG) = 0.038\n",
            "P(NN | NN) = 0.754\n",
            "P(DT | NN) = 0.095\n",
            "P(VBD | NN) = 0.049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Emission probabilities**"
      ],
      "metadata": {
        "id": "CyrMQ9toS-Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emission_prob = defaultdict(dict)\n",
        "\n",
        "for tag in emission_counts:\n",
        "    total = sum(emission_counts[tag].values())\n",
        "    for word in emission_counts[tag]:\n",
        "        emission_prob[tag][word] = emission_counts[tag][word] / total\n",
        "\n",
        "print(\"Sample Emission Probabilities (NN):\\n\")\n",
        "\n",
        "for word, prob in list(emission_prob['NN'].items())[:10]:\n",
        "    print(f\"P({word} | NN) = {prob:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8AaIHFzsSzsA",
        "outputId": "d17a42f5-670c-4595-87df-9f0f206b11ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Emission Probabilities (NN):\n",
            "\n",
            "P(is | NN) = 0.0159\n",
            "P(one | NN) = 0.0025\n",
            "P(of | NN) = 0.0414\n",
            "P(widely | NN) = 0.0008\n",
            "P(techniques | NN) = 0.0011\n",
            "P(for | NN) = 0.0143\n",
            "P(depth | NN) = 0.0003\n",
            "P(from | NN) = 0.0074\n",
            "P(stereo | NN) = 0.0011\n",
            "P(images | NN) = 0.0038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Analyze:**\n",
        "\n",
        "**o Most frequent tag transitions**"
      ],
      "metadata": {
        "id": "Xb5TVzqMTVSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "transition_pairs = Counter()\n",
        "\n",
        "for prev_tag in transition_counts:\n",
        "    for tag in transition_counts[prev_tag]:\n",
        "        transition_pairs[(prev_tag, tag)] += transition_counts[prev_tag][tag]\n",
        "\n",
        "print(\"Top 10 Most Frequent Transitions:\\n\")\n",
        "\n",
        "for pair, count in transition_pairs.most_common(10):\n",
        "    print(f\"{pair[0]} → {pair[1]} : {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4lf1qFexTG52",
        "outputId": "6918eddb-db9f-4b4c-f9f1-389bb8028ecf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Frequent Transitions:\n",
            "\n",
            "NN → NN : 2752\n",
            "NN → DT : 347\n",
            "DT → NN : 341\n",
            "NNP → NN : 208\n",
            "NN → NNP : 207\n",
            "VBD → NN : 204\n",
            "NN → VBD : 179\n",
            "NN → VBG : 164\n",
            "VBG → NN : 144\n",
            "NNP → NNP : 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**o Apply HMM tagging to a new abstract sentence.**"
      ],
      "metadata": {
        "id": "2JvOGViKTyGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi(sentence_tokens, tags, transition_prob, emission_prob):\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    # Initialization\n",
        "    for tag in tags:\n",
        "        V[0][tag] = emission_prob[tag].get(sentence_tokens[0], 1e-6)\n",
        "        path[tag] = [tag]\n",
        "\n",
        "    # Recursion\n",
        "    for t in range(1, len(sentence_tokens)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "\n",
        "        for curr_tag in tags:\n",
        "            max_prob = 0\n",
        "            best_prev_tag = None\n",
        "\n",
        "            for prev_tag in tags:\n",
        "                prob = V[t-1][prev_tag] * \\\n",
        "                       transition_prob[prev_tag].get(curr_tag, 1e-6) * \\\n",
        "                       emission_prob[curr_tag].get(sentence_tokens[t], 1e-6)\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_prev_tag = prev_tag\n",
        "\n",
        "            V[t][curr_tag] = max_prob\n",
        "            new_path[curr_tag] = path[best_prev_tag] + [curr_tag]\n",
        "\n",
        "        path = new_path\n",
        "\n",
        "    final_tag = max(V[-1], key=V[-1].get)\n",
        "    return path[final_tag]\n",
        "\n",
        "\n",
        "# Test sentence\n",
        "test_sentence = \"The proposed model improves classification accuracy\"\n",
        "tokens = tokenize(test_sentence)\n",
        "\n",
        "tags = list(tag_counts.keys())\n",
        "predicted_tags = viterbi(tokens, tags, transition_prob, emission_prob)\n",
        "\n",
        "print(\"\\nHMM Tagging Result:\\n\")\n",
        "for word, tag in zip(tokens, predicted_tags):\n",
        "    print(word, \"→\", tag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ePTJFB6XTxF0",
        "outputId": "864f5dba-4220-4590-eb1d-6df057076965"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "HMM Tagging Result:\n",
            "\n",
            "The → DT\n",
            "proposed → VBD\n",
            "model → NN\n",
            "improves → NN\n",
            "classification → NN\n",
            "accuracy → NN\n"
          ]
        }
      ]
    }
  ]
}